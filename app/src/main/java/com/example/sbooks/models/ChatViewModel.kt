package com.example.sbooks.models

import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.google.ai.client.generativeai.GenerativeModel
import com.google.ai.client.generativeai.type.content
import com.google.ai.client.generativeai.type.generationConfig
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch

class ChatViewModel : ViewModel() {
    private val _messages = MutableStateFlow<List<Message>>(emptyList())
    val messages: StateFlow<List<Message>> = _messages.asStateFlow()

    private val _isLoading = MutableStateFlow(false)
    val isLoading: StateFlow<Boolean> = _isLoading.asStateFlow()

    private val _isChatOpen = MutableStateFlow(false)
    val isChatOpen: StateFlow<Boolean> = _isChatOpen.asStateFlow()

    private var generativeModel: GenerativeModel? = null
    private var chat: com.google.ai.client.generativeai.Chat? = null

    fun initializeChat(apiKey: String) {
        if (generativeModel != null) return

        generativeModel = GenerativeModel(
            modelName = "gemini-2.0-flash-exp",
            apiKey = apiKey,
            generationConfig = generationConfig {
                temperature = 0.7f
                topK = 40
                topP = 0.95f
                maxOutputTokens = 2048
            }
        )

        // Kh·ªüi t·∫°o chat v·ªõi history ƒë·ªÉ set system prompt
        chat = generativeModel?.startChat(
            history = listOf(
                content("user") {
                    text("B·∫°n l√† chuy√™n gia t∆∞ v·∫•n s√°ch. H√£y g·ª£i √Ω s√°ch ph√π h·ª£p, gi·∫£i th√≠ch l√Ω do. Tr·∫£ l·ªùi ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán.")
                },
                content("model") {
                    text("Xin ch√†o! T√¥i l√† tr·ª£ l√Ω t∆∞ v·∫•n s√°ch AI. H√£y cho t√¥i bi·∫øt s·ªü th√≠ch c·ªßa b·∫°n! üìö")
                }
            )
        )

        _messages.value = listOf(
            Message(
                content = "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω t∆∞ v·∫•n s√°ch AI. H√£y cho t√¥i bi·∫øt:\n\n" +
                        "‚Ä¢ B·∫°n th√≠ch ƒë·ªçc th·ªÉ lo·∫°i g√¨?\n" +
                        "‚Ä¢ T√¢m tr·∫°ng hi·ªán t·∫°i c·ªßa b·∫°n?\n" +
                        "‚Ä¢ M·ª•c ƒë√≠ch ƒë·ªçc s√°ch?\n\n" +
                        "Ho·∫∑c h·ªèi tr·ª±c ti·∫øp v·ªÅ m·ªôt cu·ªën s√°ch nh√©! üìö",
                isUser = false
            )
        )
    }

    fun toggleChat() {
        _isChatOpen.value = !_isChatOpen.value
    }

    fun closeChat() {
        _isChatOpen.value = false
    }

    fun sendMessage(userMessage: String) {
        if (userMessage.isBlank() || chat == null) return

        _messages.value = _messages.value + Message(
            content = userMessage,
            isUser = true
        )

        _isLoading.value = true

        viewModelScope.launch {
            try {
                val response = chat?.sendMessage(userMessage)
                val botMessage = response?.text ?: "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i."

                _messages.value = _messages.value + Message(
                    content = botMessage,
                    isUser = false
                )
            } catch (e: Exception) {
                _messages.value = _messages.value + Message(
                    content = "‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói: ${e.message}\n\nVui l√≤ng th·ª≠ l·∫°i sau.",
                    isUser = false
                )
            } finally {
                _isLoading.value = false
            }
        }
    }

    fun clearChat() {
        chat = generativeModel?.startChat()
        _messages.value = listOf(
            Message(
                content = "Chat ƒë√£ ƒë∆∞·ª£c l√†m m·ªõi. H√£y h·ªèi t√¥i v·ªÅ s√°ch b·∫°n mu·ªën t√¨m!",
                isUser = false
            )
        )
    }
}